---
vignette: >
  % \VignetteIndexEntry{Signature similarity}
  % \VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
date: '`r format(Sys.Date(), "%B %e, %Y")`'
output:
  html_document:
    mathjax: null   
---

```{r}
library(bugsigdbr)
library(BugSigDBStats)
library(ComplexHeatmap)
library(ontologyIndex)
library(ontologySimilarity)
```

# Helper functions

Function to pull out author and year of publication from a signature name:

```{r}
.getAuthorYear <- function(dat, sname)
{
    stopifnot(length(sname) == 1 && is.character(sname))
    id <- unlist(strsplit(sname, "_"))[1]
    stopifnot(grepl("^bsdb:", id))
    id <- sub("^bsdb:", "", id)
    id <- unlist(strsplit(id, "/"))
    sdat <- subset(dat, Study == paste0("Study ", id[1]) &
                        Experiment == paste0("Experiment ", id[2]) &
                        `Signature page name` == paste0("Signature ", id[3]))
    author <- sdat$Authors
    aspl <- unlist(strsplit(author, " "))[1]
    year <- sdat$Year
    cond <- sdat$Condition
    ay <- paste0(aspl, year)
    ay <- paste(ay, cond, sep = "_")
    return(ay)
}
```

Function to build a short name for a signature name:

```{r}
.getShortName <- function(sname)
{
    stopifnot(grepl("^bsdb:", sname))
    spl <- unlist(strsplit(sname, ":"))
    paste(spl[1], spl[2], sep = ":")
}
```

Function to parse out condition from signature names:

```{r}
.getCondition <- function(sigs)
{
    spl <- strsplit(sigs, "_")
    spl <- vapply(spl, `[`, character(1), x = 2)
    spl <- strsplit(spl, ":")
    spl <- vapply(spl, `[`, character(1), x = 1)
    return(spl)
}
```

Function to parse out direction from signature names:

```{r}
.getDirection <- function(sigs)
{
    spl <- strsplit(sigs, "_")
    spl <- vapply(spl, function(x) x[length(x)], character(1))
    return(spl)
}
```

# Obtain the data
```{r}
dat <- bugsigdbr::importBugSigDB()
onto <- BugSigDBStats:::.getNcbiTaxonomyObo()
# onto <- ontologyIndex::get_ontology("http://purl.obolibrary.org/obo/ncbitaxon.obo")
```

# Semantic similarity on mixed taxonomic levels

Focus on fecal samples and signatures with at least 5 taxa.

```{r}
dat.feces <- subset(dat, `Body site` == "feces")
ind <- lengths(dat.feces[["NCBI Taxonomy IDs"]]) > 4
dat.feces <- dat.feces[ind,]
```

Pull out signatures based on NCBI Taxonomy IDs:

```{r}
sigs <- bugsigdbr::getSignatures(dat.feces, tax.id.type = "ncbi")
sigs <- lapply(sigs, function(s) paste0("NCBITaxon:", s))
utax <- unique(unlist(sigs))
nt <- utax[!(utax %in% onto$id)]
sigs <- lapply(sigs, function(s) setdiff(s, nt))
```

Compute semantic similarity:

```{r}
sim.mat <- ontologySimilarity::get_sim_grid(ontology = onto, term_sets = sigs)
sim.mat[1:5,1:5]
```

# Hierarchical clustering on the semantic similarity matrix

```{r}
hc <- stats::hclust(stats::as.dist(1 - sim.mat), method = "ward.D")
clus <- stats::cutree(hc, 5)
head(clus)
d <- data.frame(label = names(clus), count = lengths(sigs[names(clus)]))
head(d)
```

# Jaccard matrix on genus level

```{r}
sigs.genus <- bugsigdbr::getSignatures(dat.feces,
                                       tax.id.type = "metaphlan",
                                       tax.level = "genus",
                                       exact.tax.level = FALSE)
mydists <- BugSigDBStats::calcPairwiseOverlaps(sigs.genus)
signames <- unique(c(mydists$name1, mydists$name2))
jmat <- matrix(0, nrow=length(signames), ncol=length(signames), dimnames=list(signames, signames))
diag(jmat) <- 1
for (i in seq_len(nrow(mydists)))
{
    jmat[mydists[i, "name2"], mydists[i, "name1"]] <- mydists[i, "jaccard"]
    jmat[mydists[i, "name1"], mydists[i, "name2"]] <- mydists[i, "jaccard"]
}
jmat[1:5,1:5]
```

Correlation between semantic similarity and Jaccard similarity:

```{r}
.fcor <- function(i) cor(jmat[i,], sim.mat[rownames(jmat)[i], colnames(jmat)])
cors <- vapply(seq_len(nrow(jmat)), .fcor, numeric(1))
summary(cors)
```

# Heatmap comparison

Color ramp from 0.01 quantile to 0.99 quantile

```{r, fig.width = 10, fig.height = 10}
quantile(as.vector(sim.mat), 0.01)
quantile(as.vector(sim.mat), 0.99)
col2 <- circlize::colorRamp2(c(0,0.8012), c("#EEEEEE", "red"))

h2 <- ComplexHeatmap::Heatmap(sim.mat[rownames(jmat),rownames(jmat)], 
                              name = "semsim",
                              col = col2,
                              # column_km = 6,
                              # row_km = 6,
                              row_title = "signatures",
                              column_title = "signatures",
                              show_row_names=FALSE,
                              show_column_names=FALSE)

col <- circlize::colorRamp2(c(0,1/3), c("#EEEEEE", "red"))
h1 <- Heatmap(jmat[,column_order(h2)], 
              col = col,
              cluster_columns = FALSE,
              show_row_names = FALSE,
              show_column_names = FALSE,
              name = "jaccard")

h2 + h1
```

Zoom into a cluster:

```{r}
h2 <- draw(h2)
ro <- ComplexHeatmap::row_order(h2)
rd <- ComplexHeatmap::row_dend(h2)
str(rd, max.level = 2)
```

Cut dendrogram at specified height ...
```{r}
hd <- cut(rd, 2.90)
par(mar = c(0,0,4,20))
par(cex = 0.5)
plot(hd$lower[[1]], horiz = TRUE)
```

... or specified number of clusters:

```{r}
##  for hierarchical clustering
clus <- stats::cutree(as.hclust(rd), 5) 

## for k-means
#clus <- rep(seq_along(ro), lengths(ro))  
#names(clus) <- rownames(sim.mat)[unlist(ro)]
```

# Test each cluster for over-representation of a condition 

```{r}
cond <- .getCondition(names(clus))
tab <- table(cond) # background
spl <- split(cond, clus) # numbers per cluster
spl <- lapply(spl, table) # numbers per cluster
smat <- vapply(spl, function(x) x[names(tab)], integer(length(tab)))
smat[is.na(smat)] <- 0
rownames(smat) <- names(tab)
rs <- rowSums(smat)
cs <- colSums(smat)
total <- sum(tab)
```

Function for constructing 2x2 contingency table for one condition and one cluster at a time:

```{r}
getContingency <- function(co, cl, m, rs, cs, total) 
{
    both <- m[co,cl]
    one <- rs[co] - both
    two <- cs[cl] - both
    all <- total - one - two - both
    unname(c(both, two, one, all))
}

getContingency("COVID-19", 2, smat, rs, cs, total)
```

Build all condition/cluster combinations for testing:

```{r}
combs <- expand.grid(rownames(smat), seq_len(ncol(smat)))
conts <- apply(combs, 1, function(x) getContingency(x[1], x[2], smat, rs, cs, total)) 
conts <- t(conts)
rownames(conts) <- apply(combs, 1, function(x) paste(x, collapse = "."))
ind <- conts[,1] > 4
conts <- conts[ind,]
combs <- combs[ind,]
```

Test for over-representation using Fisher's exact test:

```{r}
fisherp <- function(x) fisher.test(matrix(x, nrow = 2), 
                       alternative = "greater")$p.value 
ps <- apply(conts, 1, fisherp)
adjp <- p.adjust(ps, method = "BH")
res <- data.frame(condition = combs[,1], 
                  cluster = combs[,2],
                  PVAL = ps,
                  ADJ.PVAL = adjp)
res <- res[order(ps),]
head(res, n = 10)
```

# Test each condition for semantic similarity

```{r}
dir <- .getDirection(rownames(sim.mat))
cond <- .getCondition(rownames(sim.mat))
ays <- vapply(rownames(sim.mat), .getAuthorYear, character(1), dat = dat) 
ays <- strsplit(unname(ays), "_")
ays <- vapply(ays, `[`, character(1), x = 1)
```

Select conditions studied in at least two studies:

```{r}
spl <- split(ays, cond)
spl <- lapply(spl, unique)
lens <- lengths(spl)
names(lens) <- names(spl)
lens <- sort(lens, decreasing = TRUE)
conds.to.test <- names(lens)[lens > 1] # 36 conditions
```

Function for testing signatures of a condition of interest:

```{r}
.testCondition <- function(condition, sim.mat, direction = "UP")
{
    ind <- which(cond == condition & dir == direction)
    if(length(ind) < 2) p <- NA
    else p <- ontologySimilarity::get_sim_p(sim.mat, group = ind)
    return(p)
}
```

```{r}
ps.up <- vapply(conds.to.test, .testCondition, numeric(1), sim.mat = sim.mat)
ps.up <- sort(ps.up)
data.frame(CONDITION = names(ps.up), PVAL = ps.up, NR.STUDIES = lens[names(ps.up)])
ps.down <- vapply(conds.to.test, .testCondition, numeric(1),sim.mat, direction = "DOWN")
ps.down <- sort(ps.down)
data.frame(CONDITION = names(ps.down), PVAL = ps.down, NR.STUDIES = lens[names(ps.down)])
```


